{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13378a56-3b73-428f-978a-e27a38929685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive TCR-peptide-MHC binding prediction benchmark...\n",
      "Configuration: ExperimentConfig(seed=42, device='cuda', n_runs=3, test_size=0.2, val_size=0.1, batch_size=32, epochs=5, lr=0.0002, esm_model_name='facebook/esm2_t12_35M_UR50D', esm_freeze_layers=6, d_model=128, kmer_range=(3, 5), hash_features=100000, cnn_channels=[32, 64, 128], cnn_kernel_sizes=[3, 5, 7], lstm_hidden=128, lstm_layers=2, retrieval_top_k=200, tcr_knn_k=[1, 5, 10])\n",
      "Loading and preparing data...\n",
      "Data split: Train=16993, Val=2479, Test=4992\n",
      "\n",
      "============================================================\n",
      "Running B2_Frozen_ESM...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.4811, AUPRC: 0.2579\n",
      "Run 2/3\n",
      "  AUC: 0.4811, AUPRC: 0.2579\n",
      "Run 3/3\n",
      "  AUC: 0.4811, AUPRC: 0.2579\n",
      "\n",
      "============================================================\n",
      "Running B3_KMer_LR...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.3881, AUPRC: 0.1729\n",
      "Run 2/3\n",
      "  AUC: 0.3881, AUPRC: 0.1729\n",
      "Run 3/3\n",
      "  AUC: 0.3881, AUPRC: 0.1729\n",
      "\n",
      "============================================================\n",
      "Running B3_KMer_MLP...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.4905, AUPRC: 0.2087\n",
      "Run 2/3\n",
      "  AUC: 0.4905, AUPRC: 0.2087\n",
      "Run 3/3\n",
      "  AUC: 0.4905, AUPRC: 0.2087\n",
      "\n",
      "============================================================\n",
      "Running B7_TCRdist_k1...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "Run 2/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "Run 3/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "\n",
      "============================================================\n",
      "Running B7_TCRdist_k5...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "Run 2/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "Run 3/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "\n",
      "============================================================\n",
      "Running B7_TCRdist_k10...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "Run 2/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "Run 3/3\n",
      "  AUC: 0.5000, AUPRC: 0.2234\n",
      "\n",
      "============================================================\n",
      "Running B8_PeptideMHC_Prior...\n",
      "============================================================\n",
      "Run 1/3\n",
      "  AUC: 0.5094, AUPRC: 0.2328\n",
      "Run 2/3\n",
      "  AUC: 0.4859, AUPRC: 0.2149\n",
      "Run 3/3\n",
      "  AUC: 0.4947, AUPRC: 0.2231\n",
      "\n",
      "====================================================================================================\n",
      "EXPERIMENT RESULTS SUMMARY\n",
      "====================================================================================================\n",
      "Metric                      ACCURACY              AUC            AUPRC        PRECISION           RECALL\n",
      "Model                                                                                                   \n",
      "B2_Frozen_ESM        0.7524 ± 0.0000  0.4811 ± 0.0000  0.2579 ± 0.0000  0.3506 ± 0.0000  0.1274 ± 0.0000\n",
      "B3_KMer_LR           0.7766 ± 0.0000  0.3881 ± 0.0000  0.1729 ± 0.0000  0.0000 ± 0.0000  0.0000 ± 0.0000\n",
      "B3_KMer_MLP          0.5863 ± 0.0000  0.4905 ± 0.0000  0.2087 ± 0.0000  0.2020 ± 0.0000  0.2888 ± 0.0000\n",
      "B7_TCRdist_k1        0.7766 ± 0.0000  0.5000 ± 0.0000  0.2234 ± 0.0000  0.0000 ± 0.0000  0.0000 ± 0.0000\n",
      "B7_TCRdist_k10       0.7766 ± 0.0000  0.5000 ± 0.0000  0.2234 ± 0.0000  0.0000 ± 0.0000  0.0000 ± 0.0000\n",
      "B7_TCRdist_k5        0.7766 ± 0.0000  0.5000 ± 0.0000  0.2234 ± 0.0000  0.0000 ± 0.0000  0.0000 ± 0.0000\n",
      "B8_PeptideMHC_Prior  0.4953 ± 0.0052  0.4967 ± 0.0110  0.2236 ± 0.0083  0.2210 ± 0.0056  0.4990 ± 0.0134\n",
      "\n",
      "Detailed results saved to: experiment_results.csv\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Comprehensive TCR-peptide-MHC Binding Prediction Benchmark\n",
    "# Dependencies: torch, transformers, numpy, pandas, scikit-learn, tqdm, requests, hashlib\n",
    "\n",
    "import os, sys, math, json, time, random, requests, warnings, hashlib\n",
    "from typing import List, Dict, Tuple, Set, Optional, Any, Union\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import EsmModel, EsmTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    raise ImportError(\"Please install tqdm: pip install tqdm\")\n",
    "\n",
    "# --------------------------\n",
    "# Configuration & Utils\n",
    "# --------------------------\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    n_runs: int = 3  # Multiple runs for CI\n",
    "    test_size: float = 0.2\n",
    "    val_size: float = 0.1\n",
    "    batch_size: int = 64\n",
    "    epochs: int = 10\n",
    "    lr: float = 1e-4\n",
    "    \n",
    "    # ESM config\n",
    "    esm_model_name: str = \"facebook/esm2_t12_35M_UR50D\"\n",
    "    esm_freeze_layers: int = 6\n",
    "    d_model: int = 128\n",
    "    \n",
    "    # k-mer config\n",
    "    kmer_range: Tuple[int, int] = field(default_factory=lambda: (3, 5))\n",
    "    hash_features: int = 100000\n",
    "    \n",
    "    # CNN config\n",
    "    cnn_channels: List[int] = field(default_factory=lambda: [32, 64, 128])\n",
    "    cnn_kernel_sizes: List[int] = field(default_factory=lambda: [3, 5, 7])\n",
    "    \n",
    "    # LSTM config\n",
    "    lstm_hidden: int = 128\n",
    "    lstm_layers: int = 2\n",
    "    \n",
    "    # Retrieval config\n",
    "    retrieval_top_k: int = 200\n",
    "    \n",
    "    # TCR distance config\n",
    "    tcr_knn_k: List[int] = field(default_factory=lambda: [1, 5, 10])\n",
    "\n",
    "AA_STANDARD = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "AA_SET = set(AA_STANDARD)\n",
    "AA_TO_IDX = {aa: i for i, aa in enumerate(AA_STANDARD)}\n",
    "\n",
    "# MHC pseudo-sequences\n",
    "MHC_PSEUDO_SEQUENCES = {\n",
    "    \"HLA-A*02:01\": \"GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDGETRKVKAHSQTHRVDLGTLRGYYNQSEAGSHTVQRMYGCDVGSDWRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQTTKHKWEAAHVAEQLRAYLEGTCVEWLRRYLENGKETLQRTDAPKTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGQEQRYTCHVQHEGLPKPLTLRWE\",\n",
    "    \"HLA-A*01:01\": \"GSHSMRYFFTSVSRPGRGEPRFIAMGYVDDTQFVRFDSDAASQKMEPRAPWIEQEGPEYWDRETQKAKGNEQSFRVDLRTLLGYYNQSEDGSHTIQIMYGCDVGPDGRLLRGYDQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARVAEQLRAYLEGTCVEWLRRYLENGKDKLERADPPKTHVTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRWE\",\n",
    "    \"HLA-B*07:02\": \"GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQKMEPRAPWIEQEGPEYWDRETQKAKGNEQSFRVDLRTLLGYYNQSEDGSHTIQIMYGCDVGPDGRLLRGYDQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARVAEQLRAYLEGTCVEWLRRYLENGKDKLERADPPKTHVTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRWE\"\n",
    "}\n",
    "\n",
    "def get_mhc_sequence(mhc_name: str) -> str:\n",
    "    return MHC_PSEUDO_SEQUENCES.get(mhc_name, MHC_PSEUDO_SEQUENCES[\"HLA-A*02:01\"])\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def aa_to_onehot(sequence: str, max_len: int = 50) -> np.ndarray:\n",
    "    \"\"\"Convert amino acid sequence to one-hot encoding\"\"\"\n",
    "    seq = sequence.upper()[:max_len]\n",
    "    encoding = np.zeros((max_len, len(AA_STANDARD)))\n",
    "    for i, aa in enumerate(seq):\n",
    "        if aa in AA_TO_IDX:\n",
    "            encoding[i, AA_TO_IDX[aa]] = 1\n",
    "    return encoding\n",
    "\n",
    "def aa_to_indices(sequence: str, max_len: int = 50) -> np.ndarray:\n",
    "    \"\"\"Convert amino acid sequence to indices\"\"\"\n",
    "    seq = sequence.upper()[:max_len]\n",
    "    indices = np.zeros(max_len, dtype=np.long)\n",
    "    for i, aa in enumerate(seq):\n",
    "        if aa in AA_TO_IDX:\n",
    "            indices[i] = AA_TO_IDX[aa]\n",
    "    return indices\n",
    "\n",
    "# --------------------------\n",
    "# Data Management\n",
    "# --------------------------\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self, config: ExperimentConfig):\n",
    "        self.config = config\n",
    "        self.df_train = None\n",
    "        self.df_val = None\n",
    "        self.df_test = None\n",
    "        \n",
    "    def load_and_split_data(self, data_path: str = \"data.csv\"):\n",
    "        \"\"\"Load data and create train/val/test splits\"\"\"\n",
    "        # Create demo data if not exists\n",
    "        if not os.path.exists(data_path):\n",
    "            self._create_demo_data(data_path)\n",
    "        \n",
    "        df = pd.read_csv(data_path)\n",
    "        df = self._preprocess_data(df)\n",
    "        \n",
    "        # Generate negatives\n",
    "        df_with_negs = self._build_negatives(df)\n",
    "        \n",
    "        # Split data\n",
    "        self._split_data(df_with_negs)\n",
    "        \n",
    "        print(f\"Data split: Train={len(self.df_train)}, Val={len(self.df_val)}, Test={len(self.df_test)}\")\n",
    "        \n",
    "    def _create_demo_data(self, path: str):\n",
    "        \"\"\"Create demonstration dataset\"\"\"\n",
    "        demo_data = [\n",
    "            [\"CDR3\", \"MHC\", \"Epitope\"],\n",
    "            [\"CASSLEETQYF\", \"HLA-A*02:01\", \"GILGFVFTL\"],\n",
    "            [\"CASSFRGTQYF\", \"HLA-A*02:01\", \"NLVPMVATV\"],\n",
    "            [\"CASRPGLAGGRPEQYF\", \"HLA-A*02:01\", \"TPRVTGGGAM\"],\n",
    "            [\"CSVEGGSTDTQYF\", \"HLA-A*02:01\", \"ELAGIGILTV\"],\n",
    "            [\"CASSQDTQYF\", \"HLA-A*02:01\", \"LLWNGPMAV\"],\n",
    "            [\"CAWRNTGQLYF\", \"HLA-A*02:01\", \"KLVALGINAV\"],\n",
    "            [\"CASTLESGQYF\", \"HLA-A*02:01\", \"VTEHDTLLY\"],\n",
    "            [\"CASSPPRVYNEQFF\", \"HLA-A*02:01\", \"LLWNGPMAV\"],\n",
    "            [\"CASSPGQGAYNEQFF\", \"HLA-A*02:01\", \"GILGFVFTL\"],\n",
    "            [\"CASSLEETQYF\", \"HLA-A*01:01\", \"TTPESANL\"],\n",
    "            [\"CASSFRGTQYF\", \"HLA-B*07:02\", \"APRTLVYLL\"],\n",
    "            # Add more diverse examples\n",
    "            [\"CASSRGQGVYNEQFF\", \"HLA-A*02:01\", \"FLKEKGGL\"],\n",
    "            [\"CASSPRGTDTQYF\", \"HLA-A*02:01\", \"IMDQVPFSV\"],\n",
    "            [\"CASSFDRVGDNEQFF\", \"HLA-A*02:01\", \"KLGGALQAK\"],\n",
    "            [\"CASSLVGAGGRPEQYF\", \"HLA-A*02:01\", \"GVYDGREHTV\"],\n",
    "            [\"CASSQVGQGAYNEQFF\", \"HLA-A*01:01\", \"IVDCLTEMY\"],\n",
    "            [\"CASSLGQGAVGEQFF\", \"HLA-B*07:02\", \"FPVRPQVPL\"],\n",
    "            [\"CASSITGQGDNEQFF\", \"HLA-A*02:01\", \"YLQPRTFLL\"],\n",
    "            [\"CASSFGQGAYNEQFF\", \"HLA-A*02:01\", \"ALWEIQQVV\"],\n",
    "        ]\n",
    "        \n",
    "        with open(path, \"w\") as f:\n",
    "            for row in demo_data:\n",
    "                f.write(\",\".join(row) + \"\\n\")\n",
    "    \n",
    "    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean and preprocess data\"\"\"\n",
    "        df = df.copy()\n",
    "        df[\"CDR3\"] = df[\"CDR3\"].astype(str).str.upper()\n",
    "        df[\"MHC\"] = df[\"MHC\"].astype(str).str.upper()\n",
    "        df[\"Epitope\"] = df[\"Epitope\"].astype(str).str.upper()\n",
    "        df = df.dropna().drop_duplicates()\n",
    "        df = df[df[\"Epitope\"].map(lambda p: all(ch in AA_SET for ch in p))]\n",
    "        df = df[df[\"CDR3\"].map(lambda p: all(ch in AA_SET for ch in p))]\n",
    "        return df\n",
    "    \n",
    "    def _build_negatives(self, df: pd.DataFrame, k_neg: int = 4) -> pd.DataFrame:\n",
    "        \"\"\"Generate negative samples\"\"\"\n",
    "        df = df.copy()\n",
    "        df[\"label\"] = 1\n",
    "        \n",
    "        # Group peptides by length\n",
    "        peps_by_len = defaultdict(list)\n",
    "        for pep in df[\"Epitope\"].unique():\n",
    "            peps_by_len[len(pep)].append(pep)\n",
    "        \n",
    "        # Generate negatives\n",
    "        negatives = []\n",
    "        for _, row in df.iterrows():\n",
    "            cdr3, mhc, pep = row[\"CDR3\"], row[\"MHC\"], row[\"Epitope\"]\n",
    "            \n",
    "            # Same-length peptide shuffling\n",
    "            candidates = peps_by_len[len(pep)]\n",
    "            neg_peps = [p for p in candidates if p != pep]\n",
    "            \n",
    "            if len(neg_peps) >= k_neg:\n",
    "                selected_negs = random.sample(neg_peps, k_neg)\n",
    "            else:\n",
    "                selected_negs = neg_peps + [self._mutate_peptide(pep) for _ in range(k_neg - len(neg_peps))]\n",
    "            \n",
    "            for neg_pep in selected_negs:\n",
    "                negatives.append({\"CDR3\": cdr3, \"MHC\": mhc, \"Epitope\": neg_pep, \"label\": 0})\n",
    "        \n",
    "        df_neg = pd.DataFrame(negatives)\n",
    "        return pd.concat([df, df_neg], ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    def _mutate_peptide(self, peptide: str, n_mut: int = 1) -> str:\n",
    "        \"\"\"Mutate peptide for negative sampling\"\"\"\n",
    "        s = list(peptide)\n",
    "        for _ in range(n_mut):\n",
    "            pos = random.randint(0, len(s) - 1)\n",
    "            original = s[pos]\n",
    "            s[pos] = random.choice([aa for aa in AA_STANDARD if aa != original])\n",
    "        return \"\".join(s)\n",
    "    \n",
    "    def _split_data(self, df: pd.DataFrame):\n",
    "        \"\"\"Split data by epitope to avoid leakage\"\"\"\n",
    "        positive_epitopes = df[df[\"label\"] == 1][\"Epitope\"].unique()\n",
    "        random.shuffle(positive_epitopes)\n",
    "        \n",
    "        n_test = int(len(positive_epitopes) * self.config.test_size)\n",
    "        n_val = int(len(positive_epitopes) * self.config.val_size)\n",
    "        \n",
    "        test_epitopes = set(positive_epitopes[:n_test])\n",
    "        val_epitopes = set(positive_epitopes[n_test:n_test + n_val])\n",
    "        train_epitopes = set(positive_epitopes[n_test + n_val:])\n",
    "        \n",
    "        self.df_test = df[df[\"Epitope\"].isin(test_epitopes)].reset_index(drop=True)\n",
    "        self.df_val = df[df[\"Epitope\"].isin(val_epitopes)].reset_index(drop=True)\n",
    "        self.df_train = df[df[\"Epitope\"].isin(train_epitopes)].reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluation Metrics\n",
    "# --------------------------\n",
    "\n",
    "class Evaluator:\n",
    "    @staticmethod\n",
    "    def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Compute evaluation metrics\"\"\"\n",
    "        return {\n",
    "            \"auc\": roc_auc_score(y_true, y_prob),\n",
    "            \"auprc\": average_precision_score(y_true, y_prob),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"precision\": ((y_pred == 1) & (y_true == 1)).sum() / max(1, (y_pred == 1).sum()),\n",
    "            \"recall\": ((y_pred == 1) & (y_true == 1)).sum() / max(1, (y_true == 1).sum()),\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggregate_metrics(metrics_list: List[Dict[str, float]]) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Aggregate metrics from multiple runs with CI\"\"\"\n",
    "        aggregated = {}\n",
    "        for metric in metrics_list[0].keys():\n",
    "            values = [m[metric] for m in metrics_list]\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            ci_lower = mean_val - 1.96 * std_val / np.sqrt(len(values))\n",
    "            ci_upper = mean_val + 1.96 * std_val / np.sqrt(len(values))\n",
    "            \n",
    "            aggregated[metric] = {\n",
    "                \"mean\": mean_val,\n",
    "                \"std\": std_val,\n",
    "                \"ci_lower\": ci_lower,\n",
    "                \"ci_upper\": ci_upper\n",
    "            }\n",
    "        return aggregated\n",
    "\n",
    "# --------------------------\n",
    "# Base Model Classes\n",
    "# --------------------------\n",
    "\n",
    "class BaseModel:\n",
    "    def __init__(self, config: ExperimentConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def fit(self, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, df_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Return predictions and probabilities\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TemperatureScaling:\n",
    "    \"\"\"Temperature scaling for calibration\"\"\"\n",
    "    def __init__(self):\n",
    "        self.temperature = 1.0\n",
    "    \n",
    "    def fit(self, logits: np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"Fit temperature parameter\"\"\"\n",
    "        try:\n",
    "            from scipy.optimize import minimize_scalar\n",
    "            \n",
    "            def nll(temp):\n",
    "                if temp <= 0:\n",
    "                    return 1e6\n",
    "                scaled_logits = logits / temp\n",
    "                probs = 1 / (1 + np.exp(-scaled_logits))\n",
    "                probs = np.clip(probs, 1e-7, 1 - 1e-7)\n",
    "                return -np.mean(labels * np.log(probs) + (1 - labels) * np.log(1 - probs))\n",
    "            \n",
    "            result = minimize_scalar(nll, bounds=(0.1, 10.0), method='bounded')\n",
    "            self.temperature = result.x\n",
    "        except:\n",
    "            # Fallback if scipy is not available\n",
    "            self.temperature = 1.0\n",
    "    \n",
    "    def apply(self, logits: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply temperature scaling\"\"\"\n",
    "        return 1 / (1 + np.exp(-logits / self.temperature))\n",
    "\n",
    "# --------------------------\n",
    "# Dataset Classes\n",
    "# --------------------------\n",
    "\n",
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, mode: str = \"classification\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return {\n",
    "            \"cdr3\": str(row[\"CDR3\"]),\n",
    "            \"mhc\": str(row[\"MHC\"]),\n",
    "            \"epitope\": str(row[\"Epitope\"]),\n",
    "            \"label\": float(row[\"label\"])\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"cdr3\": [item[\"cdr3\"] for item in batch],\n",
    "        \"mhc\": [item[\"mhc\"] for item in batch],\n",
    "        \"epitope\": [item[\"epitope\"] for item in batch],\n",
    "        \"labels\": torch.tensor([item[\"label\"] for item in batch], dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "# --------------------------\n",
    "# B2: Frozen ESM + Linear Head (Simplified for demo)\n",
    "# --------------------------\n",
    "\n",
    "class FrozenESMModel(BaseModel):\n",
    "    def __init__(self, config: ExperimentConfig):\n",
    "        super().__init__(config)\n",
    "        self.classifier = None\n",
    "        self.temp_scaling = TemperatureScaling()\n",
    "        \n",
    "    def fit(self, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "        # Extract simple features (length-based for demo)\n",
    "        train_features = self._extract_simple_features(df_train)\n",
    "        val_features = self._extract_simple_features(df_val)\n",
    "        \n",
    "        train_labels = df_train[\"label\"].values\n",
    "        val_labels = df_val[\"label\"].values\n",
    "        \n",
    "        # Train linear classifier\n",
    "        self.classifier = LogisticRegression(max_iter=1000, random_state=self.config.seed)\n",
    "        self.classifier.fit(train_features, train_labels)\n",
    "        \n",
    "        # Temperature scaling\n",
    "        val_logits = self.classifier.decision_function(val_features)\n",
    "        self.temp_scaling.fit(val_logits, val_labels)\n",
    "        \n",
    "    def _extract_simple_features(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Extract simple features for demo purposes\"\"\"\n",
    "        features = []\n",
    "        for _, row in df.iterrows():\n",
    "            cdr3_len = len(row[\"CDR3\"])\n",
    "            epitope_len = len(row[\"Epitope\"])\n",
    "            mhc_type = 1 if \"A*02:01\" in row[\"MHC\"] else 0\n",
    "            \n",
    "            # Simple amino acid composition features\n",
    "            cdr3_aa_counts = [row[\"CDR3\"].count(aa) for aa in \"ACDEFGHIKLMNPQRSTVWY\"]\n",
    "            epitope_aa_counts = [row[\"Epitope\"].count(aa) for aa in \"ACDEFGHIKLMNPQRSTVWY\"]\n",
    "            \n",
    "            feature_vector = [cdr3_len, epitope_len, mhc_type] + cdr3_aa_counts + epitope_aa_counts\n",
    "            features.append(feature_vector)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def predict(self, df_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        test_features = self._extract_simple_features(df_test)\n",
    "        \n",
    "        logits = self.classifier.decision_function(test_features)\n",
    "        probs = self.temp_scaling.apply(logits)\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        \n",
    "        return preds, probs\n",
    "\n",
    "# --------------------------\n",
    "# B3: k-mer + LR/MLP\n",
    "# --------------------------\n",
    "\n",
    "class KmerFeatureExtractor:\n",
    "    def __init__(self, kmer_range: Tuple[int, int], hash_features: int):\n",
    "        self.kmer_range = kmer_range\n",
    "        self.hash_features = hash_features\n",
    "        self.vectorizer = HashingVectorizer(\n",
    "            n_features=hash_features,\n",
    "            analyzer='char',\n",
    "            ngram_range=kmer_range,\n",
    "            binary=True\n",
    "        )\n",
    "        \n",
    "    def extract_kmers(self, sequence: str) -> Set[str]:\n",
    "        \"\"\"Extract k-mers from sequence\"\"\"\n",
    "        kmers = set()\n",
    "        for k in range(self.kmer_range[0], self.kmer_range[1] + 1):\n",
    "            for i in range(len(sequence) - k + 1):\n",
    "                kmers.add(sequence[i:i + k])\n",
    "        return kmers\n",
    "    \n",
    "    def fit_transform(self, sequences: List[str]) -> np.ndarray:\n",
    "        \"\"\"Fit and transform sequences to k-mer features\"\"\"\n",
    "        kmer_strings = []\n",
    "        for seq in sequences:\n",
    "            kmers = self.extract_kmers(seq)\n",
    "            kmer_strings.append(\" \".join(kmers))\n",
    "        \n",
    "        return self.vectorizer.fit_transform(kmer_strings).toarray()\n",
    "    \n",
    "    def transform(self, sequences: List[str]) -> np.ndarray:\n",
    "        \"\"\"Transform sequences to k-mer features\"\"\"\n",
    "        kmer_strings = []\n",
    "        for seq in sequences:\n",
    "            kmers = self.extract_kmers(seq)\n",
    "            kmer_strings.append(\" \".join(kmers))\n",
    "        \n",
    "        return self.vectorizer.transform(kmer_strings).toarray()\n",
    "\n",
    "class KmerModel(BaseModel):\n",
    "    def __init__(self, config: ExperimentConfig, model_type: str = \"lr\"):\n",
    "        super().__init__(config)\n",
    "        self.model_type = model_type\n",
    "        self.tcr_extractor = KmerFeatureExtractor(config.kmer_range, config.hash_features // 3)\n",
    "        self.mhc_extractor = KmerFeatureExtractor(config.kmer_range, config.hash_features // 3)\n",
    "        self.pep_extractor = KmerFeatureExtractor(config.kmer_range, config.hash_features // 3)\n",
    "        self.classifier = None\n",
    "        self.temp_scaling = TemperatureScaling()\n",
    "        \n",
    "    def fit(self, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "        # Extract features\n",
    "        train_features = self._extract_features(df_train, fit=True)\n",
    "        val_features = self._extract_features(df_val, fit=False)\n",
    "        \n",
    "        train_labels = df_train[\"label\"].values\n",
    "        val_labels = df_val[\"label\"].values\n",
    "        \n",
    "        # Train classifier\n",
    "        if self.model_type == \"lr\":\n",
    "            self.classifier = LogisticRegression(max_iter=1000, random_state=self.config.seed)\n",
    "        else:  # mlp\n",
    "            self.classifier = MLPClassifier(\n",
    "                hidden_layer_sizes=(256, 128),\n",
    "                max_iter=500,\n",
    "                random_state=self.config.seed\n",
    "            )\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            self.classifier.fit(train_features, train_labels)\n",
    "        \n",
    "        # Temperature scaling\n",
    "        if hasattr(self.classifier, 'decision_function'):\n",
    "            val_logits = self.classifier.decision_function(val_features)\n",
    "        else:\n",
    "            val_probs = self.classifier.predict_proba(val_features)[:, 1]\n",
    "            val_logits = np.log(val_probs / (1 - val_probs + 1e-8))\n",
    "        \n",
    "        self.temp_scaling.fit(val_logits, val_labels)\n",
    "        \n",
    "    def _extract_features(self, df: pd.DataFrame, fit: bool = False) -> np.ndarray:\n",
    "        \"\"\"Extract k-mer features\"\"\"\n",
    "        tcr_seqs = df[\"CDR3\"].tolist()\n",
    "        mhc_seqs = [get_mhc_sequence(mhc) for mhc in df[\"MHC\"].tolist()]\n",
    "        pep_seqs = df[\"Epitope\"].tolist()\n",
    "        \n",
    "        if fit:\n",
    "            tcr_features = self.tcr_extractor.fit_transform(tcr_seqs)\n",
    "            mhc_features = self.mhc_extractor.fit_transform(mhc_seqs)\n",
    "            pep_features = self.pep_extractor.fit_transform(pep_seqs)\n",
    "        else:\n",
    "            tcr_features = self.tcr_extractor.transform(tcr_seqs)\n",
    "            mhc_features = self.mhc_extractor.transform(mhc_seqs)\n",
    "            pep_features = self.pep_extractor.transform(pep_seqs)\n",
    "        \n",
    "        return np.hstack([tcr_features, mhc_features, pep_features])\n",
    "    \n",
    "    def predict(self, df_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        test_features = self._extract_features(df_test, fit=False)\n",
    "        \n",
    "        if hasattr(self.classifier, 'decision_function'):\n",
    "            logits = self.classifier.decision_function(test_features)\n",
    "        else:\n",
    "            probs = self.classifier.predict_proba(test_features)[:, 1]\n",
    "            logits = np.log(probs / (1 - probs + 1e-8))\n",
    "        \n",
    "        probs = self.temp_scaling.apply(logits)\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        \n",
    "        return preds, probs\n",
    "\n",
    "# --------------------------\n",
    "# B7: TCR Distance + k-NN (Simplified)\n",
    "# --------------------------\n",
    "\n",
    "def compute_tcr_distance(tcr1: str, tcr2: str) -> float:\n",
    "    \"\"\"Simplified TCR distance (edit distance)\"\"\"\n",
    "    # Simple Hamming distance for same length, edit distance otherwise\n",
    "    if len(tcr1) == len(tcr2):\n",
    "        return sum(c1 != c2 for c1, c2 in zip(tcr1, tcr2)) / len(tcr1)\n",
    "    else:\n",
    "        # Simple edit distance approximation\n",
    "        from difflib import SequenceMatcher\n",
    "        return 1.0 - SequenceMatcher(None, tcr1, tcr2).ratio()\n",
    "\n",
    "class TCRDistanceModel(BaseModel):\n",
    "    def __init__(self, config: ExperimentConfig, k: int = 5):\n",
    "        super().__init__(config)\n",
    "        self.k = k\n",
    "        self.train_data = None\n",
    "        \n",
    "    def fit(self, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "        # Store training data for k-NN\n",
    "        self.train_data = df_train.copy()\n",
    "        \n",
    "    def predict(self, df_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        for _, test_row in df_test.iterrows():\n",
    "            test_tcr = test_row[\"CDR3\"]\n",
    "            test_mhc = test_row[\"MHC\"]\n",
    "            test_epitope = test_row[\"Epitope\"]\n",
    "            \n",
    "            # Find k nearest neighbors based on TCR distance\n",
    "            distances = []\n",
    "            for _, train_row in self.train_data.iterrows():\n",
    "                train_tcr = train_row[\"CDR3\"]\n",
    "                \n",
    "                # Only consider same MHC-epitope pairs\n",
    "                if train_row[\"MHC\"] == test_mhc and train_row[\"Epitope\"] == test_epitope:\n",
    "                    dist = compute_tcr_distance(test_tcr, train_tcr)\n",
    "                    distances.append((dist, train_row[\"label\"]))\n",
    "            \n",
    "            if distances:\n",
    "                # Sort by distance and take k nearest\n",
    "                distances.sort(key=lambda x: x[0])\n",
    "                k_nearest = distances[:self.k]\n",
    "                \n",
    "                # Vote\n",
    "                positive_votes = sum([1 for _, label in k_nearest if label == 1])\n",
    "                prob = positive_votes / len(k_nearest)\n",
    "                pred = 1 if prob > 0.5 else 0\n",
    "            else:\n",
    "                # No similar examples found\n",
    "                prob = 0.0\n",
    "                pred = 0\n",
    "            \n",
    "            predictions.append(pred)\n",
    "            probabilities.append(prob)\n",
    "        \n",
    "        return np.array(predictions), np.array(probabilities)\n",
    "\n",
    "# --------------------------\n",
    "# B8: Peptide-MHC Prior + Random TCR\n",
    "# --------------------------\n",
    "\n",
    "class PeptideMHCPriorModel(BaseModel):\n",
    "    def __init__(self, config: ExperimentConfig):\n",
    "        super().__init__(config)\n",
    "        self.mhc_binding_scores = {}\n",
    "        \n",
    "    def fit(self, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "        # Compute peptide-MHC binding frequencies from training data\n",
    "        for _, row in df_train.iterrows():\n",
    "            key = (row[\"Epitope\"], row[\"MHC\"])\n",
    "            if key not in self.mhc_binding_scores:\n",
    "                self.mhc_binding_scores[key] = {\"pos\": 0, \"neg\": 0}\n",
    "            \n",
    "            if row[\"label\"] == 1:\n",
    "                self.mhc_binding_scores[key][\"pos\"] += 1\n",
    "            else:\n",
    "                self.mhc_binding_scores[key][\"neg\"] += 1\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        for key in self.mhc_binding_scores:\n",
    "            total = self.mhc_binding_scores[key][\"pos\"] + self.mhc_binding_scores[key][\"neg\"]\n",
    "            self.mhc_binding_scores[key] = self.mhc_binding_scores[key][\"pos\"] / total if total > 0 else 0.5\n",
    "        \n",
    "    def predict(self, df_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        for _, row in df_test.iterrows():\n",
    "            key = (row[\"Epitope\"], row[\"MHC\"])\n",
    "            \n",
    "            if key in self.mhc_binding_scores:\n",
    "                prob = self.mhc_binding_scores[key]\n",
    "            else:\n",
    "                # Unknown peptide-MHC pair, use random\n",
    "                prob = random.random()\n",
    "            \n",
    "            pred = 1 if prob > 0.5 else 0\n",
    "            predictions.append(pred)\n",
    "            probabilities.append(prob)\n",
    "        \n",
    "        return np.array(predictions), np.array(probabilities)\n",
    "\n",
    "# --------------------------\n",
    "# Experiment Runner\n",
    "# --------------------------\n",
    "\n",
    "class ExperimentRunner:\n",
    "    def __init__(self, config: ExperimentConfig):\n",
    "        self.config = config\n",
    "        self.data_manager = DataManager(config)\n",
    "        self.evaluator = Evaluator()\n",
    "        \n",
    "    def run_all_experiments(self) -> pd.DataFrame:\n",
    "        \"\"\"Run all experiments and return results table\"\"\"\n",
    "        print(\"Loading and preparing data...\")\n",
    "        self.data_manager.load_and_split_data()\n",
    "        \n",
    "        # Simplified model set for demo\n",
    "        models = {\n",
    "            \"B2_Frozen_ESM\": FrozenESMModel,\n",
    "            \"B3_KMer_LR\": lambda config: KmerModel(config, \"lr\"),\n",
    "            \"B3_KMer_MLP\": lambda config: KmerModel(config, \"mlp\"),\n",
    "            \"B7_TCRdist_k1\": lambda config: TCRDistanceModel(config, k=1),\n",
    "            \"B7_TCRdist_k5\": lambda config: TCRDistanceModel(config, k=5),\n",
    "            \"B7_TCRdist_k10\": lambda config: TCRDistanceModel(config, k=10),\n",
    "            \"B8_PeptideMHC_Prior\": PeptideMHCPriorModel,\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for model_name, model_class in models.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Running {model_name}...\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            model_results = []\n",
    "            \n",
    "            for run in range(self.config.n_runs):\n",
    "                print(f\"Run {run + 1}/{self.config.n_runs}\")\n",
    "                \n",
    "                # Set seed for reproducibility\n",
    "                set_seed(self.config.seed + run)\n",
    "                \n",
    "                try:\n",
    "                    # Initialize and train model\n",
    "                    model = model_class(self.config)\n",
    "                    model.fit(self.data_manager.df_train, self.data_manager.df_val)\n",
    "                    \n",
    "                    # Predict on test set\n",
    "                    y_pred, y_prob = model.predict(self.data_manager.df_test)\n",
    "                    y_true = self.data_manager.df_test[\"label\"].values\n",
    "                    \n",
    "                    # Compute metrics\n",
    "                    metrics = self.evaluator.compute_metrics(y_true, y_pred, y_prob)\n",
    "                    model_results.append(metrics)\n",
    "                    \n",
    "                    print(f\"  AUC: {metrics['auc']:.4f}, AUPRC: {metrics['auprc']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  Error in {model_name} run {run + 1}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if model_results:\n",
    "                # Aggregate results\n",
    "                aggregated = self.evaluator.aggregate_metrics(model_results)\n",
    "                \n",
    "                for metric, stats in aggregated.items():\n",
    "                    results.append({\n",
    "                        \"Model\": model_name,\n",
    "                        \"Metric\": metric.upper(),\n",
    "                        \"Mean\": stats[\"mean\"],\n",
    "                        \"Std\": stats[\"std\"],\n",
    "                        \"CI_Lower\": stats[\"ci_lower\"],\n",
    "                        \"CI_Upper\": stats[\"ci_upper\"],\n",
    "                        \"CI_String\": f\"{stats['mean']:.4f} ± {1.96 * stats['std'] / np.sqrt(self.config.n_runs):.4f}\"\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def save_results(self, results_df: pd.DataFrame, output_path: str = \"experiment_results.csv\"):\n",
    "        \"\"\"Save results to CSV and print summary table\"\"\"\n",
    "        results_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Create summary table\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(\"EXPERIMENT RESULTS SUMMARY\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        # Pivot table for better readability\n",
    "        pivot_df = results_df.pivot(index=\"Model\", columns=\"Metric\", values=\"CI_String\")\n",
    "        print(pivot_df.to_string())\n",
    "        \n",
    "        print(f\"\\nDetailed results saved to: {output_path}\")\n",
    "        print(f\"{'='*100}\")\n",
    "\n",
    "# --------------------------\n",
    "# Main Function\n",
    "# --------------------------\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main experiment runner\"\"\"\n",
    "    # Configuration\n",
    "    config = ExperimentConfig(\n",
    "        seed=42,\n",
    "        n_runs=3,\n",
    "        epochs=5,  # Reduced for demo\n",
    "        batch_size=32,\n",
    "        lr=2e-4\n",
    "    )\n",
    "    \n",
    "    print(\"Starting comprehensive TCR-peptide-MHC binding prediction benchmark...\")\n",
    "    print(f\"Configuration: {config}\")\n",
    "    \n",
    "    # Run experiments\n",
    "    runner = ExperimentRunner(config)\n",
    "    results_df = runner.run_all_experiments()\n",
    "    \n",
    "    # Save and display results\n",
    "    runner.save_results(results_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bef784-ecd1-435d-a9f4-d946ff14d76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
