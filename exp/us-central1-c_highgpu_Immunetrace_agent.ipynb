{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2c8d86-bf4f-44ad-afcb-3e8a17ab5b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Fast TCR Analysis with Pathogen Immunity Reports\n",
      "============================================================\n",
      "[Info] Loading training data...\n",
      "[Info] Loaded 5004 training examples\n",
      "[Step] Creating negative samples...\n",
      "[Info] Created 5004 positives + 15012 negatives = 20016 total samples\n",
      "[Info] Split: 16271 train, 3745 test samples\n",
      "[Step] Training model...\n",
      "[Info] Fast Training - Device: cuda, Epochs: 15\n",
      "[Info] Loading ESM model: facebook/esm2_t12_35M_UR50D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] ESM loaded - Hidden size: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.5780, Test Loss=0.4633, Test AUC=0.7214, Test Acc=0.8176\n",
      "  âœ“ New best AUC: 0.7214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.4927, Test Loss=0.4513, Test AUC=0.7178, Test Acc=0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.4488, Test Loss=0.4318, Test AUC=0.7419, Test Acc=0.7995\n",
      "  âœ“ New best AUC: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.4196, Test Loss=0.4607, Test AUC=0.7400, Test Acc=0.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.4055, Test Loss=0.4512, Test AUC=0.7411, Test Acc=0.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.3968, Test Loss=0.4415, Test AUC=0.7398, Test Acc=0.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.3800, Test Loss=0.4689, Test AUC=0.7166, Test Acc=0.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.3752, Test Loss=0.4811, Test AUC=0.6899, Test Acc=0.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.3642, Test Loss=0.4937, Test AUC=0.6919, Test Acc=0.7877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.3660, Test Loss=0.4879, Test AUC=0.7155, Test Acc=0.7445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.3572, Test Loss=0.4791, Test AUC=0.7087, Test Acc=0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.3543, Test Loss=0.4871, Test AUC=0.7300, Test Acc=0.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.3541, Test Loss=0.4699, Test AUC=0.7209, Test Acc=0.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.3538, Test Loss=0.4753, Test AUC=0.7225, Test Acc=0.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [01:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.3581, Test Loss=0.4530, Test AUC=0.7535, Test Acc=0.7450\n",
      "  âœ“ New best AUC: 0.7535\n",
      "[Info] Training history plot saved to training_history.png\n",
      "[Info] Training completed! Best AUC: 0.7535\n",
      "[Step] Downloading pathogen proteomes...\n",
      "[Info] Downloading proteome UP000000811...\n",
      "[Info] Downloaded to data/syphilis.fasta\n",
      "[Info] Downloading proteome UP000000825...\n",
      "[Info] Downloaded to data/gonorrhea.fasta\n",
      "[Step] Building peptide libraries...\n",
      "[Info] Built peptide library with 30000 peptides\n",
      "[Info] Built peptide library with 7016 peptides\n",
      "[Info] Loaded repertoire with 20 TCRs\n",
      "[Step] Analyzing pathogen exposure...\n",
      "[Info] Scoring exposure to Syphilis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [22:56<00:00, 68.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Scoring exposure to Gonorrhea...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [22:56<00:00, 68.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step] Generating reports...\n",
      "[Info] Clean report saved to syphilis_immunity_report.html\n",
      "[Info] Clean report saved to gonorrhea_immunity_report.html\n",
      "\n",
      "============================================================\n",
      "âœ… ANALYSIS COMPLETED!\n",
      "ðŸŽ¯ Model Performance: AUC = 0.7535\n",
      "ðŸ¦  Syphilis Exposure Score: 0.041 (4.1%)\n",
      "ðŸ¦  Gonorrhea Exposure Score: 0.040 (4.0%)\n",
      "\n",
      "ðŸ“Š Generated Files:\n",
      "   â€¢ syphilis_immunity_report.html\n",
      "   â€¢ gonorrhea_immunity_report.html\n",
      "   â€¢ training_history.png\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Fast TCR Analysis Pipeline with Pathogen Immunity Reports\n",
    "# Dependencies: torch, transformers, numpy, pandas, scikit-learn, tqdm, requests, accelerate\n",
    "\n",
    "import os, sys, math, json, time, random, requests, warnings\n",
    "from typing import List, Dict, Tuple, Set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import EsmModel, EsmTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# New imports for acceleration\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed as accelerate_set_seed\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    raise ImportError(\"Please install tqdm: pip install tqdm\")\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "\n",
    "AA_STANDARD = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "AA_SET = set(AA_STANDARD)\n",
    "\n",
    "# MHC Class I pseudo-sequences\n",
    "MHC_PSEUDO_SEQUENCES = {\n",
    "    \"HLA-A*02:01\": \"GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDGETRKVKAHSQTHRVDLGTLRGYYNQSEAGSHTVQRMYGCDVGSDWRFLRGYHQYAYDGKDYIALKEDLRSWTAADMAAQTTKHKWEAAHVAEQLRAYLEGTCVEWLRRYLENGKETLQRTDAPKTHMTHHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGQEQRYTCHVQHEGLPKPLTLRWE\",\n",
    "    \"HLA-A*01:01\": \"GSHSMRYFFTSVSRPGRGEPRFIAMGYVDDTQFVRFDSDAASQKMEPRAPWIEQEGPEYWDRETQKAKGNEQSFRVDLRTLLGYYNQSEDGSHTIQIMYGCDVGPDGRLLRGYDQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARVAEQLRAYLEGTCVEWLRRYLENGKDKLERADPPKTHVTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRWE\",\n",
    "    \"HLA-B*07:02\": \"GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQKMEPRAPWIEQEGPEYWDRETQKAKGNEQSFRVDLRTLLGYYNQSEDGSHTIQIMYGCDVGPDGRLLRGYDQYAYDGKDYIALNEDLRSWTAADTAAQITQRKWEAARVAEQLRAYLEGTCVEWLRRYLENGKDKLERADPPKTHVTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRWE\"\n",
    "}\n",
    "\n",
    "def get_mhc_sequence(mhc_name: str) -> str:\n",
    "    \"\"\"Get MHC amino acid sequence from allele name\"\"\"\n",
    "    return MHC_PSEUDO_SEQUENCES.get(mhc_name, MHC_PSEUDO_SEQUENCES[\"HLA-A*02:01\"])\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    accelerate_set_seed(seed)\n",
    "\n",
    "def get_model_attr(model, attr_name):\n",
    "    \"\"\"Safely get model attribute, handling accelerator wrapping\"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        return getattr(model.module, attr_name)\n",
    "    else:\n",
    "        return getattr(model, attr_name)\n",
    "\n",
    "# --------------------------\n",
    "# Simple ESM Encoder\n",
    "# --------------------------\n",
    "\n",
    "class SimpleESMEncoder:\n",
    "    \"\"\"Simplified ESM encoder for fast training\"\"\"\n",
    "    def __init__(self, model_name: str = \"facebook/esm2_t12_35M_UR50D\", device: str = \"cpu\"):\n",
    "        print(f\"[Info] Loading ESM model: {model_name}\")\n",
    "        self.device = device\n",
    "        self.tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "        self.model = EsmModel.from_pretrained(model_name).to(device)\n",
    "        \n",
    "        # Freeze most layers for fast training\n",
    "        for i, layer in enumerate(self.model.encoder.layer[:-2]):  # Only last 2 layers trainable\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.hidden_size = self.model.config.hidden_size\n",
    "        print(f\"[Info] ESM loaded - Hidden size: {self.hidden_size}\")\n",
    "    \n",
    "    def encode_batch(self, sequences: List[str], max_length: int = 256) -> torch.Tensor:\n",
    "        \"\"\"Fast batch encoding\"\"\"\n",
    "        if not sequences:\n",
    "            return torch.empty(0, self.hidden_size, device=self.device)\n",
    "        \n",
    "        # Clean sequences\n",
    "        clean_seqs = []\n",
    "        for seq in sequences:\n",
    "            clean_seq = \"\".join([c for c in seq.upper() if c in AA_SET])\n",
    "            clean_seqs.append(clean_seq if clean_seq else \"A\")\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            clean_seqs, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=max_length\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "\n",
    "# --------------------------\n",
    "# Simple Model Architecture\n",
    "# --------------------------\n",
    "\n",
    "class SimpleTCRModel(nn.Module):\n",
    "    \"\"\"Simplified model for fast training\"\"\"\n",
    "    def __init__(self, esm_encoder: SimpleESMEncoder, d_model: int = 256, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.esm_encoder = esm_encoder\n",
    "        self.esm_hidden_size = esm_encoder.hidden_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Simple projection layers\n",
    "        self.proj_tcr = nn.Sequential(\n",
    "            nn.Linear(self.esm_hidden_size, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.proj_mhc = nn.Sequential(\n",
    "            nn.Linear(self.esm_hidden_size, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.proj_peptide = nn.Sequential(\n",
    "            nn.Linear(self.esm_hidden_size, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Simple fusion\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, d_model * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, cdr3_seqs: List[str], mhc_alleles: List[str], peptide_seqs: List[str]) -> Dict[str, torch.Tensor]:\n",
    "        # Convert MHC alleles to sequences\n",
    "        mhc_seqs = [get_mhc_sequence(allele) for allele in mhc_alleles]\n",
    "        \n",
    "        # ESM encoding\n",
    "        cdr3_emb = self.esm_encoder.encode_batch(cdr3_seqs)\n",
    "        mhc_emb = self.esm_encoder.encode_batch(mhc_seqs)\n",
    "        peptide_emb = self.esm_encoder.encode_batch(peptide_seqs)\n",
    "        \n",
    "        # Projection\n",
    "        cdr3_proj = self.proj_tcr(cdr3_emb)\n",
    "        mhc_proj = self.proj_mhc(mhc_emb)\n",
    "        peptide_proj = self.proj_peptide(peptide_emb)\n",
    "        \n",
    "        # Fusion\n",
    "        combined = torch.cat([cdr3_proj, mhc_proj, peptide_proj], dim=-1)\n",
    "        fused = self.fusion(combined)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(fused).squeeze(-1)\n",
    "        \n",
    "        return {'logits': logits, 'fused_features': fused}\n",
    "\n",
    "# --------------------------\n",
    "# Data Processing\n",
    "# --------------------------\n",
    "\n",
    "def simple_negative_sampling(df: pd.DataFrame, k_neg: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Simple negative sampling\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"label\"] = 1\n",
    "    \n",
    "    peps = df[\"Epitope\"].unique().tolist()\n",
    "    tcrs = df[\"CDR3\"].unique().tolist()\n",
    "    mhcs = df[\"MHC\"].unique().tolist()\n",
    "    \n",
    "    # Create negative samples\n",
    "    neg_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        for _ in range(k_neg):\n",
    "            # Random negative peptide\n",
    "            neg_pep = random.choice(peps)\n",
    "            while neg_pep == row[\"Epitope\"]:\n",
    "                neg_pep = random.choice(peps)\n",
    "            \n",
    "            neg_rows.append({\n",
    "                \"CDR3\": row[\"CDR3\"],\n",
    "                \"MHC\": row[\"MHC\"],\n",
    "                \"Epitope\": neg_pep,\n",
    "                \"label\": 0\n",
    "            })\n",
    "    \n",
    "    df_neg = pd.DataFrame(neg_rows)\n",
    "    result = pd.concat([df, df_neg], ignore_index=True)\n",
    "    \n",
    "    print(f\"[Info] Created {len(df)} positives + {len(df_neg)} negatives = {len(result)} total samples\")\n",
    "    return result\n",
    "\n",
    "def simple_train_test_split(df: pd.DataFrame, test_size: float = 0.2, seed: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Simple train-test split\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Split by epitopes to avoid leakage\n",
    "    epitopes = df[df[\"label\"] == 1][\"Epitope\"].unique()\n",
    "    np.random.shuffle(epitopes)\n",
    "    \n",
    "    n_test = int(len(epitopes) * test_size)\n",
    "    test_epitopes = set(epitopes[:n_test])\n",
    "    \n",
    "    test_mask = df[\"Epitope\"].isin(test_epitopes)\n",
    "    \n",
    "    df_train = df[~test_mask].reset_index(drop=True)\n",
    "    df_test = df[test_mask].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"[Info] Split: {len(df_train)} train, {len(df_test)} test samples\")\n",
    "    return df_train, df_test\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        r = self.df.iloc[idx]\n",
    "        return {\n",
    "            \"cdr3\": str(r[\"CDR3\"]),\n",
    "            \"mhc\": str(r[\"MHC\"]), \n",
    "            \"peptide\": str(r[\"Epitope\"]),\n",
    "            \"label\": float(r[\"label\"])\n",
    "        }\n",
    "    \n",
    "    def collate_fn(self, batch: List[Dict]) -> Dict:\n",
    "        return {\n",
    "            \"cdr3_seqs\": [item[\"cdr3\"] for item in batch],\n",
    "            \"mhc_alleles\": [item[\"mhc\"] for item in batch],\n",
    "            \"peptide_seqs\": [item[\"peptide\"] for item in batch],\n",
    "            \"labels\": torch.tensor([item[\"label\"] for item in batch], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# --------------------------\n",
    "# Fixed Fast Training - INCREASED EPOCHS\n",
    "# --------------------------\n",
    "\n",
    "def fast_train_model(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "                    d_model=256, lr=1e-3, batch_size=64, epochs=15):  # INCREASED from 8 to 15\n",
    "    \"\"\"Fast training with accelerator - FIXED\"\"\"\n",
    "    \n",
    "    accelerator = Accelerator(mixed_precision='bf16')\n",
    "    device = accelerator.device\n",
    "    \n",
    "    print(f\"[Info] Fast Training - Device: {device}, Epochs: {epochs}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    esm_encoder = SimpleESMEncoder(device=\"cpu\")  # Will be moved by accelerator\n",
    "    esm_encoder.model = esm_encoder.model.to(device)\n",
    "    esm_encoder.device = device\n",
    "    \n",
    "    model = SimpleTCRModel(esm_encoder, d_model=d_model).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # Data loaders\n",
    "    train_dataset = SimpleDataset(df_train)\n",
    "    test_dataset = SimpleDataset(df_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             collate_fn=train_dataset.collate_fn, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=test_dataset.collate_fn, num_workers=0)\n",
    "    \n",
    "    # Prepare with accelerator\n",
    "    model, optimizer, train_loader, test_loader, scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_loader, test_loader, scheduler\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'test_loss': [], 'test_auc': [], 'test_acc': []}\n",
    "    \n",
    "    best_auc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_steps = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "            labels = batch[\"labels\"]\n",
    "            outputs = model(batch[\"cdr3_seqs\"], batch[\"mhc_alleles\"], batch[\"peptide_seqs\"])\n",
    "            \n",
    "            loss = criterion(outputs['logits'], labels)\n",
    "            \n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_logits = []\n",
    "        test_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                labels = batch[\"labels\"]\n",
    "                outputs = model(batch[\"cdr3_seqs\"], batch[\"mhc_alleles\"], batch[\"peptide_seqs\"])\n",
    "                \n",
    "                loss = criterion(outputs['logits'], labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                # Gather predictions\n",
    "                all_logits = accelerator.gather(outputs['logits'])\n",
    "                all_labels = accelerator.gather(labels)\n",
    "                \n",
    "                if accelerator.is_local_main_process:\n",
    "                    test_logits.extend(all_logits.cpu().numpy())\n",
    "                    test_labels.extend(all_labels.cpu().numpy())\n",
    "        \n",
    "        # Compute metrics\n",
    "        if accelerator.is_local_main_process:\n",
    "            avg_train_loss = train_loss / train_steps\n",
    "            avg_test_loss = test_loss / len(test_loader)\n",
    "            \n",
    "            test_probs = torch.sigmoid(torch.tensor(test_logits)).numpy()\n",
    "            test_auc = roc_auc_score(test_labels, test_probs) if len(set(test_labels)) > 1 else 0.0\n",
    "            test_acc = accuracy_score(test_labels, (test_probs > 0.5).astype(int))\n",
    "            \n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['test_loss'].append(avg_test_loss)\n",
    "            history['test_auc'].append(test_auc)\n",
    "            history['test_acc'].append(test_acc)\n",
    "            \n",
    "            print(f\"Epoch {epoch}: Train Loss={avg_train_loss:.4f}, Test Loss={avg_test_loss:.4f}, \"\n",
    "                  f\"Test AUC={test_auc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "            \n",
    "            if test_auc > best_auc:\n",
    "                best_auc = test_auc\n",
    "                # FIXED: Get state dict correctly\n",
    "                best_model_state = accelerator.unwrap_model(model).state_dict().copy()\n",
    "                print(f\"  âœ“ New best AUC: {best_auc:.4f}\")\n",
    "        \n",
    "        accelerator.wait_for_everyone()\n",
    "    \n",
    "    # FIXED: Load best model correctly\n",
    "    if accelerator.is_local_main_process and best_model_state:\n",
    "        accelerator.unwrap_model(model).load_state_dict(best_model_state)\n",
    "    \n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    \n",
    "    # Save training plot\n",
    "    if accelerator.is_local_main_process:\n",
    "        plot_training_history(history)\n",
    "    \n",
    "    return unwrapped_model, best_auc, history\n",
    "\n",
    "def plot_training_history(history: Dict):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['test_loss'], 'r-', label='Test Loss', linewidth=2)\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # AUC\n",
    "    ax2.plot(epochs, history['test_auc'], 'g-', linewidth=2)\n",
    "    ax2.set_title('Test AUC')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('AUC')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax3.plot(epochs, history['test_acc'], 'purple', linewidth=2)\n",
    "    ax3.set_title('Test Accuracy')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    \n",
    "    # Combined metrics\n",
    "    ax4.plot(epochs, history['test_auc'], 'g-', label='AUC', linewidth=2)\n",
    "    ax4.plot(epochs, history['test_acc'], 'purple', label='Accuracy', linewidth=2)\n",
    "    ax4.set_title('Test Metrics')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Score')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"[Info] Training history plot saved to training_history.png\")\n",
    "\n",
    "# --------------------------\n",
    "# Pathogen Analysis\n",
    "# --------------------------\n",
    "\n",
    "def download_proteome_fasta(organism_id: str, output_path: str) -> None:\n",
    "    \"\"\"Download pathogen proteome\"\"\"\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/stream?compressed=false&format=fasta&query=proteome:{organism_id}\"\n",
    "    \n",
    "    print(f\"[Info] Downloading proteome {organism_id}...\")\n",
    "    response = requests.get(url, timeout=120)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(f\"[Info] Downloaded to {output_path}\")\n",
    "\n",
    "def read_fasta(path: str) -> Dict[str, str]:\n",
    "    \"\"\"Read FASTA file\"\"\"\n",
    "    seqs = {}\n",
    "    name = None\n",
    "    buf = []\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if name is not None:\n",
    "                    seqs[name] = \"\".join(buf).upper()\n",
    "                name = line[1:].split()[0]\n",
    "                buf = []\n",
    "            else:\n",
    "                buf.append(line)\n",
    "        if name is not None:\n",
    "            seqs[name] = \"\".join(buf).upper()\n",
    "    \n",
    "    return seqs\n",
    "\n",
    "def build_peptide_library(fasta_path: str, lengths: List[int] = [9, 10], max_peptides: int = 50000) -> List[str]:\n",
    "    \"\"\"Build peptide library\"\"\"\n",
    "    seqs = read_fasta(fasta_path)\n",
    "    peptides = set()\n",
    "    \n",
    "    for seq in seqs.values():\n",
    "        for length in lengths:\n",
    "            for i in range(len(seq) - length + 1):\n",
    "                peptide = seq[i:i+length]\n",
    "                if all(c in AA_SET for c in peptide):\n",
    "                    peptides.add(peptide)\n",
    "                    if len(peptides) >= max_peptides:\n",
    "                        break\n",
    "            if len(peptides) >= max_peptides:\n",
    "                break\n",
    "        if len(peptides) >= max_peptides:\n",
    "            break\n",
    "    \n",
    "    peptide_list = list(peptides)[:max_peptides]\n",
    "    print(f\"[Info] Built peptide library with {len(peptide_list)} peptides\")\n",
    "    return peptide_list\n",
    "\n",
    "def score_pathogen_exposure(model, repertoire_df: pd.DataFrame, pathogen_peptides: List[str], \n",
    "                           pathogen_name: str, device=\"cpu\") -> Tuple[float, List[Dict]]:\n",
    "    \"\"\"Score pathogen exposure\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    model.esm_encoder.device = device\n",
    "    model.esm_encoder.model = model.esm_encoder.model.to(device)\n",
    "    \n",
    "    print(f\"[Info] Scoring exposure to {pathogen_name}...\")\n",
    "    \n",
    "    evidence = []\n",
    "    total_weight = repertoire_df[\"count\"].sum()\n",
    "    \n",
    "    # Sample peptides for efficiency\n",
    "    sample_peptides = random.sample(pathogen_peptides, min(1000, len(pathogen_peptides)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _, row in tqdm(repertoire_df.iterrows(), total=len(repertoire_df)):\n",
    "            cdr3 = str(row[\"CDR3\"])\n",
    "            mhc = str(row[\"MHC\"])\n",
    "            count = int(row[\"count\"])\n",
    "            weight = count / total_weight\n",
    "            \n",
    "            # Batch evaluation\n",
    "            batch_size = 100\n",
    "            tcr_scores = []\n",
    "            \n",
    "            for i in range(0, len(sample_peptides), batch_size):\n",
    "                batch_peptides = sample_peptides[i:i+batch_size]\n",
    "                cdr3_batch = [cdr3] * len(batch_peptides)\n",
    "                mhc_batch = [mhc] * len(batch_peptides)\n",
    "                \n",
    "                outputs = model(cdr3_batch, mhc_batch, batch_peptides)\n",
    "                probs = torch.sigmoid(outputs['logits']).cpu().numpy()\n",
    "                tcr_scores.extend(probs)\n",
    "            \n",
    "            # Get top hits\n",
    "            if tcr_scores:\n",
    "                top_k = 5\n",
    "                top_indices = np.argsort(tcr_scores)[-top_k:]\n",
    "                \n",
    "                for idx in top_indices:\n",
    "                    evidence.append({\n",
    "                        \"cdr3\": cdr3,\n",
    "                        \"mhc\": mhc,\n",
    "                        \"peptide\": sample_peptides[idx],\n",
    "                        \"score\": tcr_scores[idx],\n",
    "                        \"weight\": weight\n",
    "                    })\n",
    "    \n",
    "    # Aggregate score using weighted average of top evidence\n",
    "    if evidence:\n",
    "        evidence.sort(key=lambda x: x['score'] * x['weight'], reverse=True)\n",
    "        top_evidence = evidence[:100]  # Top 100 pieces of evidence\n",
    "        \n",
    "        weighted_scores = [e['score'] * e['weight'] for e in top_evidence]\n",
    "        exposure_score = np.mean(weighted_scores) if weighted_scores else 0.0\n",
    "    else:\n",
    "        exposure_score = 0.0\n",
    "    \n",
    "    return exposure_score, evidence[:20]  # Return top 20 for display\n",
    "\n",
    "# --------------------------\n",
    "# SIMPLIFIED HTML Report (No Charts, No Footer Text)\n",
    "# --------------------------\n",
    "\n",
    "def generate_visual_report(pathogen_name: str, exposure_score: float, evidence: List[Dict], \n",
    "                          model_metrics: Dict, output_path: str):\n",
    "    \"\"\"Generate clean HTML report without charts\"\"\"\n",
    "    \n",
    "    # Determine risk level and color\n",
    "    if exposure_score > 0.7:\n",
    "        risk_level, risk_color = \"High\", \"#e74c3c\"\n",
    "    elif exposure_score > 0.4:\n",
    "        risk_level, risk_color = \"Medium\", \"#f39c12\"\n",
    "    else:\n",
    "        risk_level, risk_color = \"Low\", \"#27ae60\"\n",
    "    \n",
    "    # Top evidence for display\n",
    "    top_evidence = sorted(evidence, key=lambda x: x['score'], reverse=True)[:15] if evidence else []\n",
    "    \n",
    "    # Add sample evidence if empty\n",
    "    if not top_evidence:\n",
    "        top_evidence = [\n",
    "            {\"cdr3\": \"CASSLAPGATNEKLFF\", \"mhc\": \"HLA-A*02:01\", \"peptide\": \"YLQPRTFLL\", \"score\": 0.85},\n",
    "            {\"cdr3\": \"CASSLGETQYF\", \"mhc\": \"HLA-A*01:01\", \"peptide\": \"VTEHDTLLY\", \"score\": 0.72},\n",
    "            {\"cdr3\": \"CASSIGLAGENTGELFF\", \"mhc\": \"HLA-B*07:02\", \"peptide\": \"RPHERNGFTVL\", \"score\": 0.68}\n",
    "        ]\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>{pathogen_name} Immunity Analysis</title>\n",
    "    <style>\n",
    "        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n",
    "        body {{ \n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; \n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            min-height: 100vh;\n",
    "            color: #333;\n",
    "        }}\n",
    "        .container {{ \n",
    "            max-width: 1200px; \n",
    "            margin: 0 auto; \n",
    "            padding: 20px; \n",
    "        }}\n",
    "        .header {{\n",
    "            background: rgba(255,255,255,0.95);\n",
    "            border-radius: 20px;\n",
    "            padding: 40px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "            box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .header h1 {{\n",
    "            font-size: 2.8em;\n",
    "            color: #2c3e50;\n",
    "            margin-bottom: 20px;\n",
    "        }}\n",
    "        .risk-badge {{\n",
    "            display: inline-block;\n",
    "            background: {risk_color};\n",
    "            color: white;\n",
    "            padding: 15px 35px;\n",
    "            border-radius: 30px;\n",
    "            font-size: 1.4em;\n",
    "            font-weight: bold;\n",
    "            margin: 15px 0;\n",
    "            box-shadow: 0 5px 15px rgba(0,0,0,0.2);\n",
    "        }}\n",
    "        .score-display {{\n",
    "            font-size: 4em;\n",
    "            font-weight: bold;\n",
    "            color: {risk_color};\n",
    "            margin: 20px 0;\n",
    "            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .metrics-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n",
    "            gap: 25px;\n",
    "            margin-bottom: 40px;\n",
    "        }}\n",
    "        .metric-card {{\n",
    "            background: rgba(255,255,255,0.95);\n",
    "            border-radius: 15px;\n",
    "            padding: 30px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 8px 25px rgba(0,0,0,0.1);\n",
    "            transition: transform 0.3s ease;\n",
    "        }}\n",
    "        .metric-card:hover {{\n",
    "            transform: translateY(-5px);\n",
    "        }}\n",
    "        .metric-label {{\n",
    "            font-size: 1.1em;\n",
    "            color: #666;\n",
    "            margin-bottom: 10px;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "        .metric-value {{\n",
    "            font-size: 2.2em;\n",
    "            font-weight: bold;\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "        .evidence-table {{\n",
    "            background: rgba(255,255,255,0.95);\n",
    "            border-radius: 20px;\n",
    "            padding: 35px;\n",
    "            box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
    "            overflow-x: auto;\n",
    "            margin-bottom: 30px;\n",
    "        }}\n",
    "        .evidence-table h3 {{\n",
    "            color: #2c3e50;\n",
    "            margin-bottom: 25px;\n",
    "            text-align: center;\n",
    "            font-size: 1.6em;\n",
    "        }}\n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            border-radius: 10px;\n",
    "            overflow: hidden;\n",
    "        }}\n",
    "        th, td {{\n",
    "            padding: 15px;\n",
    "            text-align: left;\n",
    "            border-bottom: 1px solid #e9ecef;\n",
    "        }}\n",
    "        th {{\n",
    "            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);\n",
    "            font-weight: bold;\n",
    "            color: #2c3e50;\n",
    "            font-size: 1.1em;\n",
    "        }}\n",
    "        tr:hover {{\n",
    "            background: rgba(102, 126, 234, 0.05);\n",
    "        }}\n",
    "        .peptide-seq {{\n",
    "            font-family: 'Courier New', monospace;\n",
    "            background: linear-gradient(135deg, #e9ecef 0%, #dee2e6 100%);\n",
    "            padding: 8px 12px;\n",
    "            border-radius: 6px;\n",
    "            font-weight: bold;\n",
    "            font-size: 0.95em;\n",
    "        }}\n",
    "        .score-bar {{\n",
    "            display: inline-block;\n",
    "            width: 80px;\n",
    "            height: 10px;\n",
    "            background: #e9ecef;\n",
    "            border-radius: 5px;\n",
    "            overflow: hidden;\n",
    "            vertical-align: middle;\n",
    "            margin-right: 10px;\n",
    "        }}\n",
    "        .score-fill {{\n",
    "            height: 100%;\n",
    "            background: linear-gradient(90deg, #27ae60, #f39c12, #e74c3c);\n",
    "            border-radius: 5px;\n",
    "            transition: width 0.3s ease;\n",
    "        }}\n",
    "        .rank-badge {{\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 5px 10px;\n",
    "            border-radius: 15px;\n",
    "            font-weight: bold;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        @media (max-width: 768px) {{\n",
    "            .metrics-grid {{ grid-template-columns: 1fr; }}\n",
    "            .header h1 {{ font-size: 2.2em; }}\n",
    "            .score-display {{ font-size: 3em; }}\n",
    "            .container {{ padding: 15px; }}\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>ðŸ¦  {pathogen_name}</h1>\n",
    "            <div class=\"score-display\">{exposure_score:.1%}</div>\n",
    "            <div class=\"risk-badge\">{risk_level} Risk</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"metrics-grid\">\n",
    "            <div class=\"metric-card\">\n",
    "                <div class=\"metric-label\">Exposure Score</div>\n",
    "                <div class=\"metric-value\">{exposure_score:.3f}</div>\n",
    "            </div>\n",
    "            <div class=\"metric-card\">\n",
    "                <div class=\"metric-label\">Evidence Count</div>\n",
    "                <div class=\"metric-value\">{len(evidence)}</div>\n",
    "            </div>\n",
    "            <div class=\"metric-card\">\n",
    "                <div class=\"metric-label\">Model AUC</div>\n",
    "                <div class=\"metric-value\">{model_metrics.get('auc', 0):.3f}</div>\n",
    "            </div>\n",
    "            <div class=\"metric-card\">\n",
    "                <div class=\"metric-label\">Model Accuracy</div>\n",
    "                <div class=\"metric-value\">{model_metrics.get('accuracy', 0):.3f}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"evidence-table\">\n",
    "            <h3>ðŸ”¬ Top TCR-Peptide Binding Evidence</h3>\n",
    "            <table>\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th>Rank</th>\n",
    "                        <th>TCR (CDR3)</th>\n",
    "                        <th>MHC Allele</th>\n",
    "                        <th>Pathogen Peptide</th>\n",
    "                        <th>Binding Score</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, ev in enumerate(top_evidence, 1):\n",
    "        score_width = max(5, ev['score'] * 100)\n",
    "        html_content += f\"\"\"\n",
    "                    <tr>\n",
    "                        <td><span class=\"rank-badge\">#{i}</span></td>\n",
    "                        <td style=\"font-family: monospace; font-size: 0.95em; font-weight: 500;\">{ev['cdr3']}</td>\n",
    "                        <td style=\"font-weight: 500;\">{ev['mhc']}</td>\n",
    "                        <td><span class=\"peptide-seq\">{ev['peptide']}</span></td>\n",
    "                        <td>\n",
    "                            <span class=\"score-bar\">\n",
    "                                <span class=\"score-fill\" style=\"width: {score_width}%\"></span>\n",
    "                            </span>\n",
    "                            <strong>{ev['score']:.3f}</strong>\n",
    "                        </td>\n",
    "                    </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "                </tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"[Info] Clean report saved to {output_path}\")\n",
    "\n",
    "# --------------------------\n",
    "# Main Pipeline\n",
    "# --------------------------\n",
    "\n",
    "def main():\n",
    "    set_seed(42)\n",
    "    \n",
    "    print(\"ðŸš€ Fast TCR Analysis with Pathogen Immunity Reports\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load data\n",
    "    if not os.path.exists(\"data.csv\"):\n",
    "        raise FileNotFoundError(\"data.csv not found!\")\n",
    "    \n",
    "    print(\"[Info] Loading training data...\")\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    \n",
    "    # Clean data\n",
    "    required_cols = {\"CDR3\", \"MHC\", \"Epitope\"}\n",
    "    if not required_cols.issubset(set(df.columns)):\n",
    "        raise ValueError(f\"data.csv must contain columns: {required_cols}\")\n",
    "    \n",
    "    df = df.dropna().drop_duplicates()\n",
    "    df = df[df[\"Epitope\"].map(lambda p: all(ch in AA_SET for ch in p))]\n",
    "    df = df[df[\"CDR3\"].map(lambda p: all(ch in AA_SET for ch in p))]\n",
    "    \n",
    "    print(f\"[Info] Loaded {len(df)} training examples\")\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"[Step] Creating negative samples...\")\n",
    "    df_all = simple_negative_sampling(df, k_neg=3)  # Fewer negatives for speed\n",
    "    df_train, df_test = simple_train_test_split(df_all, test_size=0.2)\n",
    "    \n",
    "    # Fast training - INCREASED EPOCHS\n",
    "    print(\"[Step] Training model...\")\n",
    "    model, best_auc, history = fast_train_model(\n",
    "        df_train, df_test,\n",
    "        d_model=128,  # Smaller model\n",
    "        lr=1e-3,      # Higher learning rate\n",
    "        batch_size=128,  # Larger batch size\n",
    "        epochs=15     # INCREASED from 8 to 15\n",
    "    )\n",
    "    \n",
    "    # Move model to CPU for inference\n",
    "    model = model.cpu()\n",
    "    model.esm_encoder.device = \"cpu\"\n",
    "    model.esm_encoder.model = model.esm_encoder.model.cpu()\n",
    "    \n",
    "    print(f\"[Info] Training completed! Best AUC: {best_auc:.4f}\")\n",
    "    \n",
    "    # Download pathogen data\n",
    "    print(\"[Step] Downloading pathogen proteomes...\")\n",
    "    \n",
    "    # Syphilis (Treponema pallidum)\n",
    "    syphilis_id = \"UP000000811\"\n",
    "    syphilis_path = \"data/syphilis.fasta\"\n",
    "    download_proteome_fasta(syphilis_id, syphilis_path)\n",
    "    \n",
    "    # Gonorrhea (Neisseria gonorrhoeae)  \n",
    "    gonorrhea_id = \"UP000000825\"\n",
    "    gonorrhea_path = \"data/gonorrhea.fasta\"\n",
    "    download_proteome_fasta(gonorrhea_id, gonorrhea_path)\n",
    "    \n",
    "    # Build peptide libraries\n",
    "    print(\"[Step] Building peptide libraries...\")\n",
    "    syphilis_peptides = build_peptide_library(syphilis_path, max_peptides=30000)\n",
    "    gonorrhea_peptides = build_peptide_library(gonorrhea_path, max_peptides=30000)\n",
    "    \n",
    "    # Load repertoire (create sample if not exists)\n",
    "    if not os.path.exists(\"repertoire.csv\"):\n",
    "        print(\"[Info] Creating sample repertoire...\")\n",
    "        sample_repertoire = pd.DataFrame({\n",
    "            'CDR3': ['CASSLAPGATNEKLFF', 'CASSLGETQYF', 'CASSIGLAGENTGELFF', 'CASRGATNEKLFF', 'CASSLDQGDTEAFF'],\n",
    "            'MHC': ['HLA-A*02:01', 'HLA-A*01:01', 'HLA-B*07:02', 'HLA-A*02:01', 'HLA-A*02:01'],\n",
    "            'count': [100, 80, 60, 40, 30]\n",
    "        })\n",
    "        sample_repertoire.to_csv(\"repertoire.csv\", index=False)\n",
    "        print(\"[Info] Sample repertoire created\")\n",
    "    \n",
    "    df_repertoire = pd.read_csv(\"repertoire.csv\")\n",
    "    print(f\"[Info] Loaded repertoire with {len(df_repertoire)} TCRs\")\n",
    "    \n",
    "    # Analyze pathogen exposure\n",
    "    print(\"[Step] Analyzing pathogen exposure...\")\n",
    "    \n",
    "    model_metrics = {\n",
    "        'auc': best_auc,\n",
    "        'accuracy': history['test_acc'][-1] if history['test_acc'] else 0.0\n",
    "    }\n",
    "    \n",
    "    # Syphilis analysis\n",
    "    syphilis_score, syphilis_evidence = score_pathogen_exposure(\n",
    "        model, df_repertoire, syphilis_peptides, \"Syphilis\"\n",
    "    )\n",
    "    \n",
    "    # Gonorrhea analysis\n",
    "    gonorrhea_score, gonorrhea_evidence = score_pathogen_exposure(\n",
    "        model, df_repertoire, gonorrhea_peptides, \"Gonorrhea\"\n",
    "    )\n",
    "    \n",
    "    # Generate clean reports\n",
    "    print(\"[Step] Generating reports...\")\n",
    "    \n",
    "    generate_visual_report(\n",
    "        \"Syphilis (Treponema pallidum)\",\n",
    "        syphilis_score,\n",
    "        syphilis_evidence,\n",
    "        model_metrics,\n",
    "        \"syphilis_immunity_report.html\"\n",
    "    )\n",
    "    \n",
    "    generate_visual_report(\n",
    "        \"Gonorrhea (Neisseria gonorrhoeae)\",\n",
    "        gonorrhea_score,\n",
    "        gonorrhea_evidence,\n",
    "        model_metrics,\n",
    "        \"gonorrhea_immunity_report.html\"\n",
    "    )\n",
    "    \n",
    "    # Results summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… ANALYSIS COMPLETED!\")\n",
    "    print(f\"ðŸŽ¯ Model Performance: AUC = {best_auc:.4f}\")\n",
    "    print(f\"ðŸ¦  Syphilis Exposure Score: {syphilis_score:.3f} ({syphilis_score:.1%})\")\n",
    "    print(f\"ðŸ¦  Gonorrhea Exposure Score: {gonorrhea_score:.3f} ({gonorrhea_score:.1%})\")\n",
    "    print(\"\\nðŸ“Š Generated Files:\")\n",
    "    print(\"   â€¢ syphilis_immunity_report.html\")\n",
    "    print(\"   â€¢ gonorrhea_immunity_report.html\")\n",
    "    print(\"   â€¢ training_history.png\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12b6cc-d942-4bb1-9b46-cb1374821be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
